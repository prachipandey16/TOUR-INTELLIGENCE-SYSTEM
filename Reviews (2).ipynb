{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Io05YlcjQr1J"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "from nltk.corpus.reader.api import *\n",
        "from nltk.tokenize import *\n",
        "\n",
        "TITLE = re.compile(r\"^\\[t\\](.*)$\")  # [t] Title\n",
        "FEATURES = re.compile(\n",
        "    r\"((?:(?:\\w+\\s)+)?\\w+)\\[((?:\\+|\\-)\\d)\\]\"\n",
        ")  # find 'feature' in feature[+3]\n",
        "NOTES = re.compile(r\"\\[(?!t)(p|u|s|cc|cs)\\]\")  # find 'p' in camera[+2][p]\n",
        "SENT = re.compile(r\"##(.*)$\")  # find tokenized sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IZs63GLaQ1id"
      },
      "outputs": [],
      "source": [
        "class Review:\n",
        "    \"\"\"\n",
        "    A Review is the main block of a ReviewsCorpusReader.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, title=None, review_lines=None):\n",
        "        \"\"\"\n",
        "        :param title: the title of the review.\n",
        "        :param review_lines: the list of the ReviewLines that belong to the Review.\n",
        "        \"\"\"\n",
        "        self.title = title\n",
        "        if review_lines is None:\n",
        "            self.review_lines = []\n",
        "        else:\n",
        "            self.review_lines = review_lines\n",
        "\n",
        "    def add_line(self, review_line):\n",
        "        \"\"\"\n",
        "        Add a line (ReviewLine) to the review.\n",
        "\n",
        "        :param review_line: a ReviewLine instance that belongs to the Review.\n",
        "        \"\"\"\n",
        "        assert isinstance(review_line, ReviewLine)\n",
        "        self.review_lines.append(review_line)\n",
        "\n",
        "    def features(self):\n",
        "        \"\"\"\n",
        "        Return a list of features in the review. Each feature is a tuple made of\n",
        "        the specific item feature and the opinion strength about that feature.\n",
        "\n",
        "        :return: all features of the review as a list of tuples (feat, score).\n",
        "        :rtype: list(tuple)\n",
        "        \"\"\"\n",
        "        features = []\n",
        "        for review_line in self.review_lines:\n",
        "            features.extend(review_line.features)\n",
        "        return features\n",
        "\n",
        "    def sents(self):\n",
        "        \"\"\"\n",
        "        Return all tokenized sentences in the review.\n",
        "\n",
        "        :return: all sentences of the review as lists of tokens.\n",
        "        :rtype: list(list(str))\n",
        "        \"\"\"\n",
        "        return [review_line.sent for review_line in self.review_lines]\n",
        "\n",
        "    def __repr__(self):\n",
        "        return 'Review(title=\"{}\", review_lines={})'.format(\n",
        "            self.title, self.review_lines\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m36L0z9WRKLx"
      },
      "outputs": [],
      "source": [
        "class ReviewLine:\n",
        "    \"\"\"\n",
        "    A ReviewLine represents a sentence of the review, together with (optional)\n",
        "    annotations of its features and notes about the reviewed item.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sent, features=None, notes=None):\n",
        "        self.sent = sent\n",
        "        if features is None:\n",
        "            self.features = []\n",
        "        else:\n",
        "            self.features = features\n",
        "\n",
        "        if notes is None:\n",
        "            self.notes = []\n",
        "        else:\n",
        "            self.notes = notes\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"ReviewLine(features={}, notes={}, sent={})\".format(\n",
        "            self.features, self.notes, self.sent\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DjRj2LVGRY7z"
      },
      "outputs": [],
      "source": [
        "class ReviewsCorpusReader(CorpusReader):\n",
        "    \"\"\"\n",
        "    Reader for the Customer Review Data dataset by Hu, Liu (2004).\n",
        "    Note: we are not applying any sentence tokenization at the moment, just word\n",
        "    tokenization.\n",
        "\n",
        "        >>> from nltk.corpus import product_reviews_1\n",
        "        >>> camera_reviews = product_reviews_1.reviews('Canon_G3.txt')\n",
        "        >>> review = camera_reviews[0]\n",
        "        >>> review.sents()[0]\n",
        "        ['i', 'recently', 'purchased', 'the', 'canon', 'powershot', 'g3', 'and', 'am',\n",
        "        'extremely', 'satisfied', 'with', 'the', 'purchase', '.']\n",
        "        >>> review.features()\n",
        "        [('canon powershot g3', '+3'), ('use', '+2'), ('picture', '+2'),\n",
        "        ('picture quality', '+1'), ('picture quality', '+1'), ('camera', '+2'),\n",
        "        ('use', '+2'), ('feature', '+1'), ('picture quality', '+3'), ('use', '+1'),\n",
        "        ('option', '+1')]\n",
        "\n",
        "    We can also reach the same information directly from the stream:\n",
        "\n",
        "        >>> product_reviews_1.features('Canon_G3.txt')\n",
        "        [('canon powershot g3', '+3'), ('use', '+2'), ...]\n",
        "\n",
        "    We can compute stats for specific product features:\n",
        "\n",
        "        >>> n_reviews = len([(feat,score) for (feat,score) in product_reviews_1.features('Canon_G3.txt') if feat=='picture'])\n",
        "        >>> tot = sum([int(score) for (feat,score) in product_reviews_1.features('Canon_G3.txt') if feat=='picture'])\n",
        "        >>> mean = tot / n_reviews\n",
        "        >>> print(n_reviews, tot, mean)\n",
        "        15 24 1.6\n",
        "    \"\"\"\n",
        "\n",
        "    CorpusView = StreamBackedCorpusView\n",
        "\n",
        "    def __init__(\n",
        "        self, root, fileids, word_tokenizer=WordPunctTokenizer(), encoding=\"utf8\"\n",
        "    ):\n",
        "        \"\"\"\n",
        "        :param root: The root directory for the corpus.\n",
        "        :param fileids: a list or regexp specifying the fileids in the corpus.\n",
        "        :param word_tokenizer: a tokenizer for breaking sentences or paragraphs\n",
        "            into words. Default: `WordPunctTokenizer`\n",
        "        :param encoding: the encoding that should be used to read the corpus.\n",
        "        \"\"\"\n",
        "\n",
        "        CorpusReader.__init__(self, root, fileids, encoding)\n",
        "        self._word_tokenizer = word_tokenizer\n",
        "        self._readme = \"README.txt\"\n",
        "\n",
        "    def features(self, fileids=None):\n",
        "        \"\"\"\n",
        "        Return a list of features. Each feature is a tuple made of the specific\n",
        "        item feature and the opinion strength about that feature.\n",
        "\n",
        "        :param fileids: a list or regexp specifying the ids of the files whose\n",
        "            features have to be returned.\n",
        "        :return: all features for the item(s) in the given file(s).\n",
        "        :rtype: list(tuple)\n",
        "        \"\"\"\n",
        "        if fileids is None:\n",
        "            fileids = self._fileids\n",
        "        elif isinstance(fileids, str):\n",
        "            fileids = [fileids]\n",
        "        return concat(\n",
        "            [\n",
        "                self.CorpusView(fileid, self._read_features, encoding=enc)\n",
        "                for (fileid, enc) in self.abspaths(fileids, True)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def reviews(self, fileids=None):\n",
        "        \"\"\"\n",
        "        Return all the reviews as a list of Review objects. If `fileids` is\n",
        "        specified, return all the reviews from each of the specified files.\n",
        "\n",
        "        :param fileids: a list or regexp specifying the ids of the files whose\n",
        "            reviews have to be returned.\n",
        "        :return: the given file(s) as a list of reviews.\n",
        "        \"\"\"\n",
        "        if fileids is None:\n",
        "            fileids = self._fileids\n",
        "        return concat(\n",
        "            [\n",
        "                self.CorpusView(fileid, self._read_review_block, encoding=enc)\n",
        "                for (fileid, enc) in self.abspaths(fileids, True)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def sents(self, fileids=None):\n",
        "        \"\"\"\n",
        "        Return all sentences in the corpus or in the specified files.\n",
        "\n",
        "        :param fileids: a list or regexp specifying the ids of the files whose\n",
        "            sentences have to be returned.\n",
        "        :return: the given file(s) as a list of sentences, each encoded as a\n",
        "            list of word strings.\n",
        "        :rtype: list(list(str))\n",
        "        \"\"\"\n",
        "        return concat(\n",
        "            [\n",
        "                self.CorpusView(path, self._read_sent_block, encoding=enc)\n",
        "                for (path, enc, fileid) in self.abspaths(fileids, True, True)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def words(self, fileids=None):\n",
        "        \"\"\"\n",
        "        Return all words and punctuation symbols in the corpus or in the specified\n",
        "        files.\n",
        "\n",
        "        :param fileids: a list or regexp specifying the ids of the files whose\n",
        "            words have to be returned.\n",
        "        :return: the given file(s) as a list of words and punctuation symbols.\n",
        "        :rtype: list(str)\n",
        "        \"\"\"\n",
        "        return concat(\n",
        "            [\n",
        "                self.CorpusView(path, self._read_word_block, encoding=enc)\n",
        "                for (path, enc, fileid) in self.abspaths(fileids, True, True)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def _read_features(self, stream):\n",
        "        features = []\n",
        "        for i in range(20):\n",
        "            line = stream.readline()\n",
        "            if not line:\n",
        "                return features\n",
        "            features.extend(re.findall(FEATURES, line))\n",
        "        return features\n",
        "\n",
        "    def _read_review_block(self, stream):\n",
        "        while True:\n",
        "            line = stream.readline()\n",
        "            if not line:\n",
        "                return []  # end of file.\n",
        "            title_match = re.match(TITLE, line)\n",
        "            if title_match:\n",
        "                review = Review(\n",
        "                    title=title_match.group(1).strip()\n",
        "                )  # We create a new review\n",
        "                break\n",
        "\n",
        "        # Scan until we find another line matching the regexp, or EOF.\n",
        "        while True:\n",
        "            oldpos = stream.tell()\n",
        "            line = stream.readline()\n",
        "            # End of file:\n",
        "            if not line:\n",
        "                return [review]\n",
        "            # Start of a new review: backup to just before it starts, and\n",
        "            # return the review we've already collected.\n",
        "            if re.match(TITLE, line):\n",
        "                stream.seek(oldpos)\n",
        "                return [review]\n",
        "            # Anything else is part of the review line.\n",
        "            feats = re.findall(FEATURES, line)\n",
        "            notes = re.findall(NOTES, line)\n",
        "            sent = re.findall(SENT, line)\n",
        "            if sent:\n",
        "                sent = self._word_tokenizer.tokenize(sent[0])\n",
        "            review_line = ReviewLine(sent=sent, features=feats, notes=notes)\n",
        "            review.add_line(review_line)\n",
        "\n",
        "    def _read_sent_block(self, stream):\n",
        "        sents = []\n",
        "        for review in self._read_review_block(stream):\n",
        "            sents.extend([sent for sent in review.sents()])\n",
        "        return sents\n",
        "\n",
        "    def _read_word_block(self, stream):\n",
        "        words = []\n",
        "        for i in range(20):  # Read 20 lines at a time.\n",
        "            line = stream.readline()\n",
        "            sent = re.findall(SENT, line)\n",
        "            if sent:\n",
        "                words.extend(self._word_tokenizer.tokenize(sent[0]))\n",
        "        return words"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
